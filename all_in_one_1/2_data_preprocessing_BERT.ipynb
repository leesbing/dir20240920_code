{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c31099-1233-47f1-90e6-9f9273735e8a",
   "metadata": {},
   "source": [
    "# 说明\n",
    "<font color=darkred size=4>BERT会根据上下文生成不同的embedding，所以不需要像 Word2Vec 一样进行很多的预处理</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a3a47-4e0c-499d-a97c-04d271169478",
   "metadata": {},
   "source": [
    "## 修改自《2_data_preprocessing_Word2Vec.ipynb》\n",
    "与 Word2Vec 板相比，preprocess_text()函数有如下改变：  \n",
    "\n",
    "**1. preprocess_text()注释了以下三个函数：**  \n",
    "- remove_unwanted_content(text)\n",
    "- remove_punctuation_and_special_chars(text)\n",
    "- remove_stopwords(text)\n",
    "\n",
    "**2. 可选使用utf-8编码 --- 还未验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6fb20c-aeae-484d-9a9b-232ae60d4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in each column:\n",
      "                  null_count  null_percentage\n",
      "Unnamed: 0                 0         0.000000\n",
      "Coder1                    44         0.497456\n",
      "Coder2                    44         0.497456\n",
      "ResponseID                 0         0.000000\n",
      "NA_column               1994        22.543810\n",
      "...                      ...              ...\n",
      "INTENTIONS2_AVG         3424        38.711136\n",
      "DomainBI                2850        32.221594\n",
      "FrameBI                 2850        32.221594\n",
      "DomainBI_FrameBI        2850        32.221594\n",
      "RACE_MajMin             2408        27.224421\n",
      "\n",
      "[118 rows x 2 columns]\n",
      "\n",
      "Total number of rows before removal: 8845\n",
      "Number of rows removed due to null values in 'letter' column: 3262\n",
      "Total number of rows after removal: 5583\n",
      "\n",
      "Preprocessing complete. Processed data saved to 'V:\\20240920\\all_in_one_1\\2_processed_data_BERT.csv'.\n",
      "\n",
      "First few rows of the processed data:\n",
      "                                              letter  \\\n",
      "0  Greeting Senator,\\n \\n  Women's Global Empower...   \n",
      "2  Hello:\\n \\n I feel that this bill should be re...   \n",
      "3  Dear Senator\\n This bell is important for advo...   \n",
      "5  Hello Mr. Senator,\\n \\n I believe that the Wom...   \n",
      "8  writing this letter urging you to please re en...   \n",
      "\n",
      "                                      processed_text  \\\n",
      "0  greeting senator,\\n \\n  women's global empower...   \n",
      "2  hello:\\n \\n i feel that this bill should be re...   \n",
      "3  dear senator\\n this bell is important for advo...   \n",
      "5  hello mr. senator,\\n \\n i believe that the wom...   \n",
      "8  writing this letter urging you to please re en...   \n",
      "\n",
      "                          punctuation_count  row_null_count  \\\n",
      "0                  {',': 3, ''': 1, '.': 5}               7   \n",
      "2  {':': 1, '-': 1, '.': 5, ',': 1, ''': 1}               6   \n",
      "3                          {'.': 3, ',': 1}               7   \n",
      "5  {'.': 7, ',': 9, ''': 5, ';': 1, '-': 1}               8   \n",
      "8                                        {}              10   \n",
      "\n",
      "                                        null_columns  word_count  is_short  \n",
      "0  coding3, ReasonifMissing, OUT, Whatisyourgende...          99     False  \n",
      "2  ReasonifMissing, OUT, Whatisyourgenderidentity...          52     False  \n",
      "3  ReasonifMissing, OUT, Whatisyourgenderidentity...          50     False  \n",
      "5  coding3, ReasonifMissing, OUT, Whatisyourgende...         152     False  \n",
      "8  NA_column, coding3, DScores, IATTaken, OUT, Wh...          16      True  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Requires: pandas, nltk (pip install pandas nltk)\n",
    "# NLTK: Make sure to download 'stopwords' with nltk.download('stopwords', quiet=True)\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return \"\", Counter(), 0\n",
    "\n",
    "    punctuation_count = Counter(char for char in str(text) if char in string.punctuation)\n",
    "\n",
    "    text = text.lower()\n",
    "    # text = unicodedata.normalize('NFKD', text).encode('utf-8', 'ignore').decode('utf-8')  #使用'utf-8'\n",
    "    # text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII') #使用'ASCII'\n",
    "\n",
    "    # text = remove_unwanted_content(text)\n",
    "    # text = remove_punctuation_and_special_chars(text)\n",
    "    # text = remove_stopwords(text)\n",
    "\n",
    "    words = text.split()\n",
    "    return text, punctuation_count, len(words)\n",
    "\n",
    "def remove_unwanted_content(text):\n",
    "    patterns = [\n",
    "        r'\\([^)]*\\)',  # Remove parenthetical notes\n",
    "        r'\\b(?:dear\\s+senator|dear|hello|hi|your honorable whomever|to whom it may concern|to senator).*?:\\s*',  # Remove greetings\n",
    "        r'\\b(?:sincerely|best regards|regards|yours truly|best|thank you).*$',  # Remove closings\n",
    "        r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\w+\\s+\\d{1,2},?\\s+\\d{4})\\b',  # Remove dates\n",
    "        r'\\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2},?\\s+\\d{4}\\b',  # Remove month-based dates\n",
    "        r'\\b(?:dear|hello|hi)\\s+(?:senator|representative|mr\\.?|mrs\\.?|ms\\.?).*?[\\s,:]',  # Remove additional greetings\n",
    "        r'\\n[A-Z\\s]+$'  # Remove remaining lines that are just names\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation_and_special_chars(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    return ' '.join([word for word in words if word not in stop_words])\n",
    "\n",
    "def handle_null_values(df):\n",
    "    null_counts = df.isnull().sum().to_frame(name='null_count')\n",
    "    null_counts['null_percentage'] = (null_counts['null_count'] / len(df)) * 100\n",
    "\n",
    "    print(\"Null values in each column:\")\n",
    "    print(null_counts)\n",
    "\n",
    "    total_rows_before = len(df)\n",
    "    df_clean = df.dropna(subset=['letter'])\n",
    "    total_rows_after = len(df_clean)\n",
    "    removed_rows = total_rows_before - total_rows_after\n",
    "\n",
    "    print(f\"\\nTotal number of rows before removal: {total_rows_before}\")\n",
    "    print(f\"Number of rows removed due to null values in 'letter' column: {removed_rows}\")\n",
    "    print(f\"Total number of rows after removal: {total_rows_after}\")\n",
    "\n",
    "    return df_clean, null_counts, removed_rows\n",
    "\n",
    "def process_data(file_path):\n",
    "    try:\n",
    "        # 读取 Excel 文件\n",
    "        df = pd.read_excel(file_path, sheet_name='sheet1')\n",
    "\n",
    "        ## Task1: replace the specific mistake characters\n",
    "        #详见《 letter列文本中的乱码及处理方法.xlsx》 \n",
    "        replacements = {\n",
    "            '‚Äô': \"'\",\n",
    "            '‚äô': \"'\",\n",
    "            '√©': \" \",\n",
    "            'Äì¬†': \" \",\n",
    "            '‚Äú': \"\\\"\",\n",
    "            '‚Äù': \"\\'\",\n",
    "            '‚Äî': \"--\",\n",
    "            '‚Ä¶': \" \",\n",
    "            '√≥': \"o\"\n",
    "        }\n",
    "        for old, new in replacements.items():\n",
    "            df['letter'] = df['letter'].str.replace(old, new, regex=False)\n",
    "            # df['processed_text'] = df['letter'].str.replace(old, new, regex=False)\n",
    "\n",
    "        df, null_counts, removed_rows = handle_null_values(df)\n",
    "\n",
    "        df['row_null_count'] = df.isnull().sum(axis=1)\n",
    "        df['null_columns'] = df.apply(lambda row: ', '.join(row.index[row.isnull()]), axis=1)\n",
    "        df['processed_text'], df['punctuation_count'], df['word_count'] = zip(*df['letter'].apply(preprocess_text))\n",
    "\n",
    "        # Handle short letters - just mark\n",
    "        mean_word_count = df['word_count'].mean()\n",
    "        std_word_count = df['word_count'].std()\n",
    "        df['is_short'] = df['word_count'] < (mean_word_count - std_word_count)\n",
    "\n",
    "        # Fill missing values for categorical and numerical columns\n",
    "        df['coding1'] = df['coding1'].fillna('unknown')\n",
    "        df['coding2'] = df['coding2'].fillna('unknown')\n",
    "        df['coding3'] = df['coding3'].fillna('unknown')\n",
    "        df['word_count'] = df['word_count'].fillna(df['word_count'].mean())\n",
    "        df['processed_text'] = df['processed_text'].fillna('')\n",
    "\n",
    "        columns = list(df.columns)\n",
    "        punctuation_index = columns.index('punctuation_count')\n",
    "        columns.insert(punctuation_index + 1, columns.pop(columns.index('row_null_count')))\n",
    "        columns.insert(punctuation_index + 2, columns.pop(columns.index('null_columns')))\n",
    "        df = df[columns]\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"V:\\20240920\\all_in_one_1\\1_merged table v1.xlsx\"\n",
    "    result_df = process_data(file_path)\n",
    "    if result_df is not None:\n",
    "        output_path = r\"V:\\20240920\\all_in_one_1\\2_processed_data_BERT.csv\"\n",
    "        result_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nPreprocessing complete. Processed data saved to '{output_path}'.\")\n",
    "        print(\"\\nFirst few rows of the processed data:\")\n",
    "        print(result_df[['letter', 'processed_text', 'punctuation_count', 'row_null_count', 'null_columns', 'word_count', 'is_short']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5f8fc-649a-4553-81ca-274253eac2eb",
   "metadata": {},
   "source": [
    "# test code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba9eb2-5bdf-413c-9790-139630b29c83",
   "metadata": {},
   "source": [
    "## 小姑娘使用的乱字符处理方法，验证无效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439b042b-b3ed-4ba7-b0dd-3140f107f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "womenAo powerao test\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "text = \"women‚Äô power‚äô test\"\n",
    "normalized_text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "print(normalized_text)  # O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21cf1a3-29c9-45d4-b10a-2bf15c449625",
   "metadata": {},
   "source": [
    "## 获取 CPU 的内核数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821ac19b-7257-4d8a-aa9e-39215225edf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 内核数量: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取 CPU 的内核数量\n",
    "cpu_count = os.cpu_count()\n",
    "print(f\"CPU 内核数量: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df41c70-05de-4fd6-88cb-152a8a0e0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 内核数量: 2.0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# 获取 CPU 的内核数量\n",
    "cpu_count = multiprocessing.cpu_count()/2\n",
    "print(f\"CPU 内核数量: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca5075-5573-4abf-b361-2250cd3f9708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_env",
   "language": "python",
   "name": "huggingface_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
